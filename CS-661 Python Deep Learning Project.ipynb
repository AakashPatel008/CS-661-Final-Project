{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a539a41d",
   "metadata": {},
   "source": [
    "### Run the below code to install all Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1adec87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\var\\anaconda\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "\n",
    "from keras import regularizers\n",
    "from keras.layers import Conv2D, Dense, BatchNormalization, Activation, Dropout, MaxPooling2D, Flatten\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2570f50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f878a0",
   "metadata": {},
   "source": [
    "### File paths import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d907a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'C:/Users/Aakash Patel/CS-661-Final-Project/train/'\n",
    "test_dir = 'C:/Users/Aakash Patel/CS-661-Final-Project/test/'\n",
    "\n",
    "row = 48\n",
    "col = 48\n",
    "classes = len(os.listdir('C:/Users/Aakash Patel/CS-661-Final-Project/train/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bc54c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train Set :\")\n",
    "\n",
    "train_count = []\n",
    "for folder in os.listdir(train_dir) :\n",
    "    print(folder, \"folder contains\\t\\t\", len(os.listdir(train_dir+folder)), \"image\")\n",
    "    train_count.append(len(os.listdir(train_dir+folder)))\n",
    "    \n",
    "print()\n",
    "\n",
    "test_count = []\n",
    "print(\"Test Set :\")\n",
    "for folder in os.listdir(test_dir) :\n",
    "    print(folder, \"folder contains\\t\\t\", len(os.listdir(test_dir+folder)), \"images\")\n",
    "    test_count.append(len(os.listdir(test_dir+folder)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a41e879",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   zoom_range=0.3,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(train_dir,\n",
    "                                                batch_size=64,\n",
    "                                                target_size=(48,48),\n",
    "                                                shuffle=True,\n",
    "                                                color_mode='grayscale',\n",
    "                                                class_mode='categorical')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_set = test_datagen.flow_from_directory(test_dir,\n",
    "                                                batch_size=64,\n",
    "                                                target_size=(48,48),\n",
    "                                                shuffle=True,\n",
    "                                                color_mode='grayscale',\n",
    "                                                class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b27978f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sad', 'Surprised']\n",
    "\n",
    "img, label = next(training_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eef4902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "\n",
    "i=random.randint(0, (img.shape[0])-1)\n",
    "image = img[i]\n",
    "labl = class_labels[label[i].argmax()]\n",
    "plt.imshow(image[:,:,0], cmap='gray')\n",
    "plt.title(labl)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6fe1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(48,48,1)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3),padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3, 3),padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer = 'adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b022d9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_path = 'ferNet.h5'\n",
    "log_dir = \"checkpoint/logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=chk_path,\n",
    "                             save_best_only=True,\n",
    "                             verbose=1,\n",
    "                             mode='min',\n",
    "                             moniter='val_accuracy')\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_accuracy', \n",
    "                          min_delta=0, \n",
    "                          patience=3, \n",
    "                          verbose=1, \n",
    "                          restore_best_weights=True)\n",
    "                        \n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "                              factor=0.2, \n",
    "                              patience=6, \n",
    "                              verbose=1, \n",
    "                              min_delta=0.0001)\n",
    "\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "csv_logger = CSVLogger('training.log')\n",
    "\n",
    "callbacks = [checkpoint, reduce_lr, csv_logger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bba8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = training_set.n // training_set.batch_size\n",
    "validation_steps = test_set.n // test_set.batch_size\n",
    "\n",
    "hist = model.fit(x=training_set,\n",
    "                  validation_data=test_set,\n",
    "                  epochs=25,\n",
    "                  callbacks=callbacks,\n",
    "                  steps_per_epoch=steps_per_epoch,\n",
    "                  validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6269e74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_trained.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57d2238",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss= hist.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "acc=hist.history['accuracy']\n",
    "val_acc=hist.history['val_accuracy']\n",
    "plt.plot(epochs, val_acc, 'y', label='Validation acc')\n",
    "plt.plot(epochs, acc, 'r', label=\"Training acc\")\n",
    "plt.title('Training and validation accuracy')\n",
    "#plt.xlable('Epochs')\n",
    "#plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b565fabe",
   "metadata": {},
   "source": [
    "### Run the Bellow Cell to run the Program.\n",
    "### Above Cell contains Tranning of the Deep learning model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d992970e",
   "metadata": {},
   "source": [
    "### Main Program to Run\n",
    "### In this find the Line mood_music=pd.read_csv(r\"C:\\Users\\Aakash Patel\\CS-661-Final-Project\\Music.csv\")\n",
    "### And Enter you file path for Music.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8276fdee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\var\\anaconda\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\var\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Detected Emotion: Happy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>name</th>\n",
       "      <th>artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>149</td>\n",
       "      <td>Down On The Corner</td>\n",
       "      <td>Creedence Clearwater Revival</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>596</td>\n",
       "      <td>United</td>\n",
       "      <td>Armin van Buuren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>147</td>\n",
       "      <td>Don't You (Forget About Me) - Remastered</td>\n",
       "      <td>Simple Minds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71</td>\n",
       "      <td>Blow</td>\n",
       "      <td>Yves V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58</td>\n",
       "      <td>Better Together</td>\n",
       "      <td>Jack Johnson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                      name  \\\n",
       "0    149                        Down On The Corner   \n",
       "1    596                                    United   \n",
       "2    147  Don't You (Forget About Me) - Remastered   \n",
       "3     71                                      Blow   \n",
       "4     58                           Better Together   \n",
       "\n",
       "                         artist  \n",
       "0  Creedence Clearwater Revival  \n",
       "1              Armin van Buuren  \n",
       "2                  Simple Minds  \n",
       "3                        Yves V  \n",
       "4                  Jack Johnson  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "from PIL import Image\n",
    "\n",
    "home_folder = 'C:/Users/Aakash Patel/CS-661-Final-Project'\n",
    "test_folder = os.path.join(home_folder, 'test')\n",
    "train_folder = os.path.join(home_folder, 'train')\n",
    "\n",
    "def load_images_from_folder(folder_path):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".JPG\"):\n",
    "            img = Image.open(os.path.join(folder_path, filename))\n",
    "            if img is not None:\n",
    "                images.append(img)\n",
    "    return images\n",
    "\n",
    "test_images = load_images_from_folder(test_folder)\n",
    "train_images = load_images_from_folder(train_folder)\n",
    "\n",
    "test_data = np.array([np.array(img) for img in test_images])\n",
    "train_data = np.array([np.array(img) for img in train_images])\n",
    "\n",
    "# Loading trained model\n",
    "my_model = load_model('model_trained.h5', compile=False)\n",
    "\n",
    "# Define the emotion labels\n",
    "class_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sad', 'Surprised']\n",
    "\n",
    "# Initialize the camera\n",
    "cap = cv2.VideoCapture(0)  \n",
    "frame_count = 0  # Counter for frames\n",
    "detected_emotion = None  \n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame.\")\n",
    "        break\n",
    "\n",
    "    # Preprocess the frame \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    \n",
    "    for (x, y, w, h) in faces:\n",
    "        face_roi = gray[y:y + h, x:x + w]\n",
    "        face_img = cv2.resize(face_roi, (48, 48))\n",
    "        face_img = face_img / 255.0  # Normalize\n",
    "\n",
    "        # Make predictions using your model\n",
    "        predictions = my_model.predict(np.array([face_img.reshape(48, 48, 1)]))\n",
    "        detected_emotion = class_labels[np.argmax(predictions)]\n",
    "\n",
    "        # Draw a rectangle around the detected face and display the emotion\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, detected_emotion, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"webcam\", frame)\n",
    "    \n",
    "    if frame_count == 25:  # Close the webcam after 1 seconds (assuming 25 frames per second)\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "# Release the camera\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Access the detected emotion after the webcam closes\n",
    "print(\"Detected Emotion:\", detected_emotion)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "mood_music=pd.read_csv(r\"C:\\Users\\Aakash Patel\\CS-661-Final-Project\\Music.csv\")\n",
    "\n",
    "mood_music=mood_music[['name', 'artist', 'mood']]\n",
    "mood_music.head()\n",
    "\n",
    "#selecting music according to moods\n",
    "\n",
    "if (detected_emotion=='Angry' or detected_emotion=='Disgust' or detected_emotion=='Fear'):\n",
    "    filter1=mood_music['mood']=='Calm' #Filtering according to 'mood' column in dataset\n",
    "    f1=mood_music.where(filter1)\n",
    "    f1=f1.dropna() #dropping rows that are empty\n",
    "    f2=f1.sample(n=5) #Displaying 5 songs\n",
    "    f2.reset_index(inplace=True)\n",
    "    f3=f2.drop([\"mood\"], axis=1)\n",
    "    display(f3)\n",
    "    \n",
    "if (detected_emotion=='Happy' or detected_emotion=='Neutral'):\n",
    "    filter1=mood_music['mood']=='Happy' #Filtering according to 'mood' column in dataset\n",
    "    f1=mood_music.where(filter1)\n",
    "    f1=f1.dropna() #dropping rows that are empty\n",
    "    f2=f1.sample(n=5) #Displaying 5 songs\n",
    "    f2.reset_index(inplace=True)\n",
    "    f3=f2.drop([\"mood\"], axis=1)\n",
    "    display(f3)\n",
    "    \n",
    "if (detected_emotion=='Sad'):\n",
    "    filter1=mood_music['mood']=='Sad' #Filtering according to 'mood' column in dataset\n",
    "    f1=mood_music.where(filter1)\n",
    "    f1=f1.dropna() #dropping rows that are empty\n",
    "    f2=f1.sample(n=5) #Displaying 5 songs\n",
    "    f2.reset_index(inplace=True)\n",
    "    f3=f2.drop([\"mood\"], axis=1)\n",
    "    display(f3)\n",
    "    \n",
    "if (detected_emotion=='Surprised'):\n",
    "    filter1=mood_music['mood']=='Energetic' #Filtering according to 'mood' column in dataset\n",
    "    f1=mood_music.where(filter1)\n",
    "    f1=f1.dropna() #dropping rows that are empty\n",
    "    f2=f1.sample(n=5) #Displaying 5 songs\n",
    "    f2.reset_index(inplace=True)\n",
    "    f3=f2.drop([\"mood\"], axis=1)\n",
    "    display(f3)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5079f16b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
